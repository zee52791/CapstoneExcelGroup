{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align: center;'>\n",
    "Group XL ETL Report\n",
    "</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents:</h2>\n",
    "<ul style='line-height: 2.2;'>\n",
    " <li><a href='#intro'>Introduction</a></li>\n",
    " <li><a href='#cpsaat'>Labor Statistics From The Current Population Survey</a></li>\n",
    " <li><a href='#10230'>Median Household Income by State: Selected years 1990 through 2019</a></li>\n",
    " <li><a href='#tablea2'>Households by Total Income: 1990 through 2019</a></li>\n",
    " <li><a href='#taba2'>Educational Attainment of People 25 Years and Over: Selected Years 1940 to 2021</a></li>\n",
    " <li><a href='#taba3'>Mean Earnings of Workers 18 Years and Over: 1975 to 2020</a></li>\n",
    " <li><a href='#howto'>Recovering Dataframes</a></li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a><h2 style='text-align: center'>Introduction</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our data capstone project we chose to examine the relationships between educational attainment and employment in the United States between the years of 2015 and 2020. In seraching for datasets relevant to our topic we found a wealth of information through the U.S. Bureau of Labor and Statistics (BLS), the U.S. Census Bureau and the National Center for Education Statistics. Using a variety of conventional tools we cleaned the data we gleaned from government servers and transformed every dataset to suit our needs. In each section we will breifly introduce the dataset we are interested in exctracting followed by an discussion of the cleaning steps involved with code provided to further illuminate our data transformation process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cpsaat'></a><h2 style='text-align: center;'>Labor Statistics From The Current Population Survey</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Current Population Survey (CPS) is survey conducted each month by the U.S. Census Bureau for the BLS which contains data relevant to employment and educational attainment. In <a href=(https://www.bls.gov/cps/tables.htm)>tables</a> provided the BLS, we were able to capture this data for our target years of 2015 to 2020 by means of web-scrapping and pandas.\n",
    "\n",
    "To upload and clean the CPS tables, we begin by importing the neccessary packages. Here we will be using numpy, pandas, re, requests, BeautifulSoup from bs4, sleep() from time and ascii_lowercase from string which we will use later to combine these datasets.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from string import ascii_lowercase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the CPSAAT for years 2016 to 2019 were available in HTML format online, we chose to use a combination of requests and BeautifulSoup to extract all the data for those years. However, because much of the column data extracted via this method was untenable to clean, since the CPSAAT has only eight columns, we hard-coded in the column names. However, the index column names were in well enough shape to be extracted and transformed into a usable condition. After importing and cleaning the data, we saved each dataset as a pickle and a CSV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2016, 2020):    \n",
    "    year = str(i)\n",
    "    url = f\"https://www.bls.gov/cps/aa{year}/cpsaat07.htm\"\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "\n",
    "    table_data = []\n",
    "    for i in soup.find_all('td'): # Finds all data with tag 'td'\n",
    "        if i.get_text() == '':\n",
    "            pass\n",
    "        elif re.findall('[a-z]', i.get_text()): # Skip alphabetic content\n",
    "            pass\n",
    "        else:\n",
    "            table_data.append(i.get_text())\n",
    "\n",
    "    clean_data = []\n",
    "    i = 0\n",
    "    while i <= len(table_data):\n",
    "        # We have eight columns in our dataframe so we will append data to raw data until we have collected eight columns worth\n",
    "        raw_data = []\n",
    "        try:\n",
    "            while len(raw_data) < 8:\n",
    "                    raw_data.append(table_data[i])\n",
    "                    i += 1\n",
    "        except:\n",
    "            break\n",
    "        clean_data.append(raw_data)\n",
    "\n",
    "    # We will grab all of the outer_index information.\n",
    "    outer_index_to_clean = []\n",
    "    for elements in soup.find_all(class_='sub0'):\n",
    "            if elements.get_text() == 'Civilian noninstitutional population': #This element belongs to the inner index\n",
    "                pass\n",
    "            else:\n",
    "                outer_index_to_clean.append(elements.get_text())\n",
    "\n",
    "    # We now proceed to accumulate all items in the inner index\n",
    "    inner_index = []\n",
    "    for items in soup.find_all(class_=['sub0', 'sub1','sub2', 'sub3', 'sub4']):\n",
    "        if items.get_text() in outer_index_to_clean:\n",
    "            pass\n",
    "        else:\n",
    "            inner_index.append(items.get_text())\n",
    "\n",
    "    # Because we are using pd.Multindex, length and order matter\n",
    "    outer_index = []\n",
    "    k = 0\n",
    "    for i in range(0, len(inner_index)):\n",
    "        try:\n",
    "            if inner_index[i+1] == 'Civilian noninstitutional population': # The inner index is periodic with respect to this category\n",
    "                outer_index.append(outer_index_to_clean[k])\n",
    "                k+=1\n",
    "            else:\n",
    "                outer_index.append(outer_index_to_clean[k])\n",
    "        except:\n",
    "            outer_index.append(outer_index_to_clean[k])\n",
    "            \n",
    "    assert len(outer_index) == len(inner_index)\n",
    "\n",
    "    # We hard code the column names (which are shared for all years of the CPSAAT)\n",
    "    column_level1 = np.array(((year + ',') * 8).split(',')[:-1])\n",
    "    column_level2 = np.array(\n",
    "        [\n",
    "        'Less than a high school diploma',\n",
    "        'High school graduates, no college',\n",
    "        'Some college or associate degree',\n",
    "        'Some college or associate degree',\n",
    "        'Some college or associate degree',\n",
    "        'Bachelor\\'s degree and higher',\n",
    "        'Bachelor\\'s degree and higher',\n",
    "        'Bachelor\\'s degree and higher'\n",
    "        ]\n",
    "    )\n",
    "    column_level3 = np.array(\n",
    "        [\n",
    "        'Less than a high school diploma',\n",
    "        'High school graduates, no college',\n",
    "        'Total',\n",
    "        'Some college, no degree',\n",
    "        'Associate degree',\n",
    "        'Total',\n",
    "        'Bachelor\\'s degree only',\n",
    "        'Advanced degree'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Now we create a list of column and index arrays\n",
    "    column_arrays = [column_level1, column_level2, column_level3]\n",
    "    index_arrays = [outer_index, inner_index]\n",
    "\n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(clean_data, index=index_arrays, columns=column_arrays)\n",
    "    df.replace(',', '', regex=True, inplace=True) # We're replacing the commas in each entry\n",
    "    df = df.astype(float) # Casting each value as a float data type\n",
    "\n",
    "    # We pickle the dataframe and export a clean CSV\n",
    "    df.to_pickle(f'clean-pickle/cpsaat-{year}.pkl')\n",
    "    df.to_csv(f'clean-csv/cpsaat-{year}.csv')\n",
    "    \n",
    "    # Be polite to the government servers: sleep for 5 seconds\n",
    "    sleep(5)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use pd.read_excel to import the final two datasets. In order to keep the dataframe in a format similiar to the previously uploaded tables, we will be using the optional arguments \"skiprows,\" to skip the text at the top of the Excel document, \"usecols,\" to designate that we only need that data between columns B and I, and \"header,\" to tell pandas that this dataset does not have a header. Next we will drop rows containing all null values before cobbling together our dataframe using our previously defined list of index arrays, and a slightly modified list of column arrays altered to reflect the year of the data gathered. Finally, we will save the cleaned CSV and pickle the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in ['2015', '2020']:\n",
    "    column_level1 = np.array(((year + ',') * 8).split(',')[:-1])\n",
    "    column_arrays = [column_level1, column_level2, column_level3]\n",
    "    xl = pd.read_excel(f\"data-capstone\\cpsaat{year}.xlsx\", skiprows=[i for i in range(0,6)], usecols=\"B:I\", header=None).dropna()\n",
    "    df = pd.DataFrame(xl.values, columns=column_arrays, index=index_arrays)\n",
    "    df.to_pickle(f'clean-pickle/cpsaat-{year}.pkl')\n",
    "    df.to_csv(f'clean-csv/cpsaat-{year}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a dummy list of lowercase characters and unpickle each of the cleaned datasets to pd.concate them into a dataframe encompassing all the target years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = list(ascii_lowercase)[0:6]\n",
    "k = 0\n",
    "for i in range(2015, 2021):\n",
    "    year = str(i)\n",
    "    dummy[k] = pd.read_pickle(f'clean-pickle/cpsaat-{year}.pkl')\n",
    "    k += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a list of our pickled dataframes and pass it into pd.concat and horizontally merge them together by passing the argument \"axis=1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = [dummy[i] for i in range(0, 6)]\n",
    "all_years = pd.concat(combine, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five rows of the resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">2015</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2016</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2019</th>\n",
       "      <th colspan=\"8\" halign=\"left\">2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Less than a high school diploma</th>\n",
       "      <th>High school graduates, no college</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Some college or associate degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Bachelor's degree and higher</th>\n",
       "      <th>Less than a high school diploma</th>\n",
       "      <th>High school graduates, no college</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Bachelor's degree and higher</th>\n",
       "      <th>Less than a high school diploma</th>\n",
       "      <th>High school graduates, no college</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Some college or associate degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Bachelor's degree and higher</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Less than a high school diploma</th>\n",
       "      <th>High school graduates, no college</th>\n",
       "      <th>Total</th>\n",
       "      <th>Some college, no degree</th>\n",
       "      <th>Associate degree</th>\n",
       "      <th>Total</th>\n",
       "      <th>Bachelor's degree only</th>\n",
       "      <th>Advanced degree</th>\n",
       "      <th>Less than a high school diploma</th>\n",
       "      <th>High school graduates, no college</th>\n",
       "      <th>...</th>\n",
       "      <th>Bachelor's degree only</th>\n",
       "      <th>Advanced degree</th>\n",
       "      <th>Less than a high school diploma</th>\n",
       "      <th>High school graduates, no college</th>\n",
       "      <th>Total</th>\n",
       "      <th>Some college, no degree</th>\n",
       "      <th>Associate degree</th>\n",
       "      <th>Total</th>\n",
       "      <th>Bachelor's degree only</th>\n",
       "      <th>Advanced degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">TOTAL</th>\n",
       "      <th>Civilian noninstitutional population</th>\n",
       "      <td>24175.0</td>\n",
       "      <td>61712.0</td>\n",
       "      <td>56263.0</td>\n",
       "      <td>35326.0</td>\n",
       "      <td>20937.0</td>\n",
       "      <td>70061.0</td>\n",
       "      <td>44086.0</td>\n",
       "      <td>25975.0</td>\n",
       "      <td>23368.0</td>\n",
       "      <td>62022.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50049.0</td>\n",
       "      <td>29778.0</td>\n",
       "      <td>19900.0</td>\n",
       "      <td>62121.0</td>\n",
       "      <td>57327.0</td>\n",
       "      <td>34076.0</td>\n",
       "      <td>23251.0</td>\n",
       "      <td>83495.0</td>\n",
       "      <td>51985.0</td>\n",
       "      <td>31510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Civilian labor force</th>\n",
       "      <td>10971.0</td>\n",
       "      <td>35322.0</td>\n",
       "      <td>37481.0</td>\n",
       "      <td>22706.0</td>\n",
       "      <td>14774.0</td>\n",
       "      <td>52133.0</td>\n",
       "      <td>32684.0</td>\n",
       "      <td>19449.0</td>\n",
       "      <td>10679.0</td>\n",
       "      <td>35649.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36672.0</td>\n",
       "      <td>22217.0</td>\n",
       "      <td>8930.0</td>\n",
       "      <td>34741.0</td>\n",
       "      <td>36401.0</td>\n",
       "      <td>20766.0</td>\n",
       "      <td>15636.0</td>\n",
       "      <td>60463.0</td>\n",
       "      <td>37340.0</td>\n",
       "      <td>23123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participation rate</th>\n",
       "      <td>45.4</td>\n",
       "      <td>57.2</td>\n",
       "      <td>66.6</td>\n",
       "      <td>64.3</td>\n",
       "      <td>70.6</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.1</td>\n",
       "      <td>74.9</td>\n",
       "      <td>45.7</td>\n",
       "      <td>57.5</td>\n",
       "      <td>...</td>\n",
       "      <td>73.3</td>\n",
       "      <td>74.6</td>\n",
       "      <td>44.9</td>\n",
       "      <td>55.9</td>\n",
       "      <td>63.5</td>\n",
       "      <td>60.9</td>\n",
       "      <td>67.2</td>\n",
       "      <td>72.4</td>\n",
       "      <td>71.8</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employed</th>\n",
       "      <td>10098.0</td>\n",
       "      <td>33402.0</td>\n",
       "      <td>35785.0</td>\n",
       "      <td>21573.0</td>\n",
       "      <td>14213.0</td>\n",
       "      <td>50792.0</td>\n",
       "      <td>31772.0</td>\n",
       "      <td>19020.0</td>\n",
       "      <td>9884.0</td>\n",
       "      <td>33801.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35850.0</td>\n",
       "      <td>21805.0</td>\n",
       "      <td>7888.0</td>\n",
       "      <td>31606.0</td>\n",
       "      <td>33570.0</td>\n",
       "      <td>19037.0</td>\n",
       "      <td>14532.0</td>\n",
       "      <td>57538.0</td>\n",
       "      <td>35286.0</td>\n",
       "      <td>22252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employment-population ratio</th>\n",
       "      <td>41.8</td>\n",
       "      <td>54.1</td>\n",
       "      <td>63.6</td>\n",
       "      <td>61.1</td>\n",
       "      <td>67.9</td>\n",
       "      <td>72.5</td>\n",
       "      <td>72.1</td>\n",
       "      <td>73.2</td>\n",
       "      <td>42.3</td>\n",
       "      <td>54.5</td>\n",
       "      <td>...</td>\n",
       "      <td>71.6</td>\n",
       "      <td>73.2</td>\n",
       "      <td>39.6</td>\n",
       "      <td>50.9</td>\n",
       "      <td>58.6</td>\n",
       "      <td>55.9</td>\n",
       "      <td>62.5</td>\n",
       "      <td>68.9</td>\n",
       "      <td>67.9</td>\n",
       "      <td>70.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      2015  \\\n",
       "                                           Less than a high school diploma   \n",
       "                                           Less than a high school diploma   \n",
       "TOTAL Civilian noninstitutional population                         24175.0   \n",
       "      Civilian labor force                                         10971.0   \n",
       "      Participation rate                                              45.4   \n",
       "      Employed                                                     10098.0   \n",
       "      Employment-population ratio                                     41.8   \n",
       "\n",
       "                                                                              \\\n",
       "                                           High school graduates, no college   \n",
       "                                           High school graduates, no college   \n",
       "TOTAL Civilian noninstitutional population                           61712.0   \n",
       "      Civilian labor force                                           35322.0   \n",
       "      Participation rate                                                57.2   \n",
       "      Employed                                                       33402.0   \n",
       "      Employment-population ratio                                       54.1   \n",
       "\n",
       "                                                                             \\\n",
       "                                           Some college or associate degree   \n",
       "                                                                      Total   \n",
       "TOTAL Civilian noninstitutional population                          56263.0   \n",
       "      Civilian labor force                                          37481.0   \n",
       "      Participation rate                                               66.6   \n",
       "      Employed                                                      35785.0   \n",
       "      Employment-population ratio                                      63.6   \n",
       "\n",
       "                                                                    \\\n",
       "                                                                     \n",
       "                                           Some college, no degree   \n",
       "TOTAL Civilian noninstitutional population                 35326.0   \n",
       "      Civilian labor force                                 22706.0   \n",
       "      Participation rate                                      64.3   \n",
       "      Employed                                             21573.0   \n",
       "      Employment-population ratio                             61.1   \n",
       "\n",
       "                                                             \\\n",
       "                                                              \n",
       "                                           Associate degree   \n",
       "TOTAL Civilian noninstitutional population          20937.0   \n",
       "      Civilian labor force                          14774.0   \n",
       "      Participation rate                               70.6   \n",
       "      Employed                                      14213.0   \n",
       "      Employment-population ratio                      67.9   \n",
       "\n",
       "                                                                         \\\n",
       "                                           Bachelor's degree and higher   \n",
       "                                                                  Total   \n",
       "TOTAL Civilian noninstitutional population                      70061.0   \n",
       "      Civilian labor force                                      52133.0   \n",
       "      Participation rate                                           74.4   \n",
       "      Employed                                                  50792.0   \n",
       "      Employment-population ratio                                  72.5   \n",
       "\n",
       "                                                                   \\\n",
       "                                                                    \n",
       "                                           Bachelor's degree only   \n",
       "TOTAL Civilian noninstitutional population                44086.0   \n",
       "      Civilian labor force                                32684.0   \n",
       "      Participation rate                                     74.1   \n",
       "      Employed                                            31772.0   \n",
       "      Employment-population ratio                            72.1   \n",
       "\n",
       "                                                            \\\n",
       "                                                             \n",
       "                                           Advanced degree   \n",
       "TOTAL Civilian noninstitutional population         25975.0   \n",
       "      Civilian labor force                         19449.0   \n",
       "      Participation rate                              74.9   \n",
       "      Employed                                     19020.0   \n",
       "      Employment-population ratio                     73.2   \n",
       "\n",
       "                                                                      2016  \\\n",
       "                                           Less than a high school diploma   \n",
       "                                           Less than a high school diploma   \n",
       "TOTAL Civilian noninstitutional population                         23368.0   \n",
       "      Civilian labor force                                         10679.0   \n",
       "      Participation rate                                              45.7   \n",
       "      Employed                                                      9884.0   \n",
       "      Employment-population ratio                                     42.3   \n",
       "\n",
       "                                                                              \\\n",
       "                                           High school graduates, no college   \n",
       "                                           High school graduates, no college   \n",
       "TOTAL Civilian noninstitutional population                           62022.0   \n",
       "      Civilian labor force                                           35649.0   \n",
       "      Participation rate                                                57.5   \n",
       "      Employed                                                       33801.0   \n",
       "      Employment-population ratio                                       54.5   \n",
       "\n",
       "                                            ...                         2019  \\\n",
       "                                            ... Bachelor's degree and higher   \n",
       "                                            ...       Bachelor's degree only   \n",
       "TOTAL Civilian noninstitutional population  ...                      50049.0   \n",
       "      Civilian labor force                  ...                      36672.0   \n",
       "      Participation rate                    ...                         73.3   \n",
       "      Employed                              ...                      35850.0   \n",
       "      Employment-population ratio           ...                         71.6   \n",
       "\n",
       "                                                            \\\n",
       "                                                             \n",
       "                                           Advanced degree   \n",
       "TOTAL Civilian noninstitutional population         29778.0   \n",
       "      Civilian labor force                         22217.0   \n",
       "      Participation rate                              74.6   \n",
       "      Employed                                     21805.0   \n",
       "      Employment-population ratio                     73.2   \n",
       "\n",
       "                                                                      2020  \\\n",
       "                                           Less than a high school diploma   \n",
       "                                           Less than a high school diploma   \n",
       "TOTAL Civilian noninstitutional population                         19900.0   \n",
       "      Civilian labor force                                          8930.0   \n",
       "      Participation rate                                              44.9   \n",
       "      Employed                                                      7888.0   \n",
       "      Employment-population ratio                                     39.6   \n",
       "\n",
       "                                                                              \\\n",
       "                                           High school graduates, no college   \n",
       "                                           High school graduates, no college   \n",
       "TOTAL Civilian noninstitutional population                           62121.0   \n",
       "      Civilian labor force                                           34741.0   \n",
       "      Participation rate                                                55.9   \n",
       "      Employed                                                       31606.0   \n",
       "      Employment-population ratio                                       50.9   \n",
       "\n",
       "                                                                             \\\n",
       "                                           Some college or associate degree   \n",
       "                                                                      Total   \n",
       "TOTAL Civilian noninstitutional population                          57327.0   \n",
       "      Civilian labor force                                          36401.0   \n",
       "      Participation rate                                               63.5   \n",
       "      Employed                                                      33570.0   \n",
       "      Employment-population ratio                                      58.6   \n",
       "\n",
       "                                                                    \\\n",
       "                                                                     \n",
       "                                           Some college, no degree   \n",
       "TOTAL Civilian noninstitutional population                 34076.0   \n",
       "      Civilian labor force                                 20766.0   \n",
       "      Participation rate                                      60.9   \n",
       "      Employed                                             19037.0   \n",
       "      Employment-population ratio                             55.9   \n",
       "\n",
       "                                                             \\\n",
       "                                                              \n",
       "                                           Associate degree   \n",
       "TOTAL Civilian noninstitutional population          23251.0   \n",
       "      Civilian labor force                          15636.0   \n",
       "      Participation rate                               67.2   \n",
       "      Employed                                      14532.0   \n",
       "      Employment-population ratio                      62.5   \n",
       "\n",
       "                                                                         \\\n",
       "                                           Bachelor's degree and higher   \n",
       "                                                                  Total   \n",
       "TOTAL Civilian noninstitutional population                      83495.0   \n",
       "      Civilian labor force                                      60463.0   \n",
       "      Participation rate                                           72.4   \n",
       "      Employed                                                  57538.0   \n",
       "      Employment-population ratio                                  68.9   \n",
       "\n",
       "                                                                   \\\n",
       "                                                                    \n",
       "                                           Bachelor's degree only   \n",
       "TOTAL Civilian noninstitutional population                51985.0   \n",
       "      Civilian labor force                                37340.0   \n",
       "      Participation rate                                     71.8   \n",
       "      Employed                                            35286.0   \n",
       "      Employment-population ratio                            67.9   \n",
       "\n",
       "                                                            \n",
       "                                                            \n",
       "                                           Advanced degree  \n",
       "TOTAL Civilian noninstitutional population         31510.0  \n",
       "      Civilian labor force                         23123.0  \n",
       "      Participation rate                              73.4  \n",
       "      Employed                                     22252.0  \n",
       "      Employment-population ratio                     70.6  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_years.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will export the clean CSV and pickle the dataframe for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years.to_csv('clean-csv/cpsaat-all-years.csv')\n",
    "all_years.to_pickle('clean-pickle/cpsaat-all-years.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='10230'></a><h2 style=\"text-align: center\">Median Household Income by State: Selected years 1990 through 2019</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we begin with importing the necessary packages: numpy, pandas, and re.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first proceed to read in the data and append each line to an empty list \"to_clean.\" As we sort through each line in the file, we are interested in grabbing only those lines which contain numeric data. Before finally appending them to \"to_clean,\" we will replace the characters \",,\" and \"\\n.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = []\n",
    "with open(r\"data-capstone/tabn102.30.csv\") as f:\n",
    "    for lines in f:\n",
    "        if re.findall('-[0-9]|[0-9]', lines):\n",
    "            to_clean.append(lines.replace(',,', '').replace('\\n', ''))\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We those entries in our list which content table values. As demonstrated by \"raw_data[0],\" to clean the data we must seperate each list entry's non-numeric content,  and eliminate the footnotes, quotation marks, and dollar signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   United States,\"$60,000\",\"$64,600\",\"$60,700\",(80),\"$58,800\",(50),\"$58,000\",(60),\"$60,200\",(60),\"$61,400\",(70),\"$62,900\",(50),\"$63,100\",(60),\"$65,700\",(70),'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = to_clean[4:-3]\n",
    "raw_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a for loop which will launder each data entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "clean_data = []\n",
    "for i in range(0, len(raw_data)):\n",
    "    clean_string = ''\n",
    "    cleaner_data = []\n",
    "    for k in range(0, len(raw_data[i])):\n",
    "        try:\n",
    "            if re.findall('[0-9],[0-9]', raw_data[i][k-1] + raw_data[i][k] + raw_data[i][k+1]): # If a comma wedged between two numbers, pass \n",
    "                pass\n",
    "            elif raw_data[i][k] == '\"': # Exclude quotation marks\n",
    "                pass\n",
    "            elif raw_data[i][k] == '$': # Exclude dollar signs\n",
    "                pass\n",
    "            else:\n",
    "                clean_string = clean_string + raw_data[i][k]\n",
    "        except:\n",
    "            pass\n",
    "    clean_string = clean_string.strip() # Remove extraneous white space\n",
    "    list_to_clean = clean_string.split(',') # We now need to remove the footnotes\n",
    "    for items in list_to_clean:\n",
    "        if re.findall('[a-z]', items): # If the list item has non-numeric content that is this data entry's index\n",
    "            index.append(items)\n",
    "        elif re.findall('\\(', items): # If the list item has a '(', exclude that item\n",
    "            pass\n",
    "        else:\n",
    "            cleaner_data.append(items)\n",
    "    clean_data.append(cleaner_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping with the format of the source document, we will use pd.Multindex to preserve the title of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Median Household Income by State: Selected years 1990 through 2019,'\n",
    "column_level1 = (title * 10).split(',')[:-1] # the last entry is ''\n",
    "column_level1 = np.array(column_level1) \n",
    "column_level1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we hard-coded the columns for the next level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_level2 = np.array([1990, 2000, 2005, 2010, 2014, 2015, 2016, 2017, 2018, 2019])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have each of our columns, we can now assemble a list of column arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_arrays = [column_level1, column_level2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming and accumulating all of the data we can now assemble the dataframe. Finally, we will cast each data entry as an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clean_data, columns=column_arrays, index=index)\n",
    "df = df.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five rows of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Median Household Income by State: Selected years 1990 through 2019</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2005</th>\n",
       "      <th>2010</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>60000</td>\n",
       "      <td>64600</td>\n",
       "      <td>60700</td>\n",
       "      <td>58800</td>\n",
       "      <td>58000</td>\n",
       "      <td>60200</td>\n",
       "      <td>61400</td>\n",
       "      <td>62900</td>\n",
       "      <td>63100</td>\n",
       "      <td>65700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>47100</td>\n",
       "      <td>52500</td>\n",
       "      <td>48400</td>\n",
       "      <td>47600</td>\n",
       "      <td>46300</td>\n",
       "      <td>48300</td>\n",
       "      <td>49300</td>\n",
       "      <td>50200</td>\n",
       "      <td>50800</td>\n",
       "      <td>51700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>82700</td>\n",
       "      <td>79400</td>\n",
       "      <td>73800</td>\n",
       "      <td>75900</td>\n",
       "      <td>77400</td>\n",
       "      <td>79200</td>\n",
       "      <td>81400</td>\n",
       "      <td>76300</td>\n",
       "      <td>75700</td>\n",
       "      <td>75500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>55000</td>\n",
       "      <td>62400</td>\n",
       "      <td>58100</td>\n",
       "      <td>55000</td>\n",
       "      <td>54100</td>\n",
       "      <td>55600</td>\n",
       "      <td>57100</td>\n",
       "      <td>59000</td>\n",
       "      <td>60300</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>42200</td>\n",
       "      <td>49500</td>\n",
       "      <td>45900</td>\n",
       "      <td>45000</td>\n",
       "      <td>44600</td>\n",
       "      <td>45300</td>\n",
       "      <td>47200</td>\n",
       "      <td>47800</td>\n",
       "      <td>47900</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Median Household Income by State: Selected years 1990 through 2019  \\\n",
       "                                                                            1990   \n",
       "United States                                              60000                   \n",
       "Alabama                                                    47100                   \n",
       "Alaska                                                     82700                   \n",
       "Arizona                                                    55000                   \n",
       "Arkansas                                                   42200                   \n",
       "\n",
       "                                                                              \n",
       "                2000   2005   2010   2014   2015   2016   2017   2018   2019  \n",
       "United States  64600  60700  58800  58000  60200  61400  62900  63100  65700  \n",
       "Alabama        52500  48400  47600  46300  48300  49300  50200  50800  51700  \n",
       "Alaska         79400  73800  75900  77400  79200  81400  76300  75700  75500  \n",
       "Arizona        62400  58100  55000  54100  55600  57100  59000  60300  62100  \n",
       "Arkansas       49500  45900  45000  44600  45300  47200  47800  47900  49000  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the resulting dataframe as both a CSV and a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clean-csv/tabn102-30.csv\")\n",
    "df.to_pickle(\"clean-pickle/tabn102-30.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tablea2'></a><h2 style='text-align: center'>Households by Total Income: 1990 through 2019</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping with the theme, to clean this data we will be using numpy, pandas, and re."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the cleaning process, from the source CSV file, we can observe that the table indicies contain the following identifiers: either the words \"RACE\" or \"IN COMBINATION,\" or, generally, a capital letter followed by a space and a number. To identify each index when we read in the data, we will use re to search for items which fit this description by way of a helper-function index_condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_condition(string):\n",
    "    index_condition = re.findall('[A-Z] [0-9]', string) or re.findall('RACE', string) or re.findall('IN COMBINATION', string)\n",
    "    return index_condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will read in each line of data. As we read in each line, we will be checking to see if it meets the requirements specified by our index_condition function. If so, we will append that item to our \"outer_index_to_clean\" list after replacing the characters \",,\", \"\\n\", and upper-casing the first letter of each word. If an item in the CSV does not meet the index_condition requirements, that content is probably numeric data. we will once again replace those characters and replace any \"N\" values with \"np.nan.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = []\n",
    "outer_index_to_clean = []\n",
    "with open(r\"data-capstone/tableA2.csv\") as f:\n",
    "    for lines in f:\n",
    "        if index_condition(lines):\n",
    "            outer_index_to_clean.append(lines.replace(',,', '').replace('\\n', '').title())\n",
    "        else:\n",
    "            to_clean.append(lines.replace(',,', '').replace('\\n', '').replace('N', str(np.nan)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting list, \"to_clean,\" contains a combination of headers, footnotes, column data, and table values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015,\"125,819\",100,9.8,9.3,9.3,11.7,16.2,12.1,15.7,7.6,8.4,\"64,631\",604,\"90,645\",758',\n",
       " '2014,\"124,587\",100,10.7,9.7,9.5,12,16.6,11.9,14.7,7.1,7.8,\"61,468\",739,\"86,763\",840',\n",
       " '2013 4,\"123,931\",100,10.5,9.9,9.2,11.8,16.5,12.4,14.5,7.1,8,\"62,425\",\"1,253\",\"87,599\",\"1,272\"',\n",
       " '2013 5,\"122,952\",100,10.4,10.1,9.5,12.1,16.9,12.9,14.2,6.9,6.9,\"60,507\",529,\"84,624\",956',\n",
       " '2012,\"122,459\",100,10.4,10.3,9.2,12.9,16.6,12.5,14.5,6.8,6.9,\"60,313\",406,\"84,262\",819']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A sample of five row entries\n",
    "to_clean[30:35]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that each table row entry begins with the year that data was recorded followed by a comma, a quotation mark, and finally the values collected for that year. We can now use re to sort our list based on this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_clean = []\n",
    "year_condition = '[0-9]\\,\\\"'\n",
    "for lines in to_clean:\n",
    "    if re.findall(year_condition, lines):\n",
    "        data_to_clean.append(lines)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the inner index of our dataframe and as well, isolate the data values for each entry. We begin by observing that, in this step, we need to accomplish a variety of cleaning tasks: we need to elimate, to the best of our ability, both footnotes and quotation marks which surround data values larger than $10^{3}$; we need to erase all extraneous commas; and we need to isolate each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['131202',\n",
       " '100',\n",
       " '9.3',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '10.9',\n",
       " '16.2',\n",
       " '11.9',\n",
       " '15.9',\n",
       " '8.3',\n",
       " '11.6',\n",
       " '70784',\n",
       " '605',\n",
       " '102316',\n",
       " '1029\"']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_index = [] # This will be where each year lives\n",
    "clean_data = [] # Our raw data will end up here\n",
    "\n",
    "for i in range(0, len(data_to_clean)):\n",
    "    dirty_data = data_to_clean[i]\n",
    "    clean_string = ''\n",
    "    for i in range(0, len(dirty_data)):\n",
    "        try:\n",
    "            if re.findall('\\\"', dirty_data[i+4]) and dirty_data[i] == ',': # If the next string four doors down from you is a quotation mark and you are a comma: pass\n",
    "                pass\n",
    "            elif re.findall(' ', dirty_data[i]): # If you are a blank space: pass\n",
    "                pass \n",
    "            elif re.findall(' ', dirty_data[i-1]) and dirty_data[i].isdigit() == True: # If you are a number and the string behind you is an empty space, you're a footnote: pass\n",
    "                pass\n",
    "            elif re.findall(' ', dirty_data[i-2]) and dirty_data[i].isdigit() == True: # If you are a number and the string two behind you is an empty space, you're a footnote: pass\n",
    "                pass\n",
    "            elif dirty_data[i] == '\"': # If you're a quotation mark, no thank you: pass\n",
    "                clean_string = clean_string + ''\n",
    "            else:\n",
    "                clean_string = clean_string + dirty_data[i]\n",
    "        except:\n",
    "            clean_string = clean_string + dirty_data[i]\n",
    "    clean_data.append(clean_string.split(',')[1:]) # The raw data is everything in this string but the first entry\n",
    "    inner_index.append(clean_string.split(',')[0]) # The year is the first entry\n",
    "# An example of a \"clean\" row\n",
    "clean_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this method succeeded in seperating these two groups of data, as evidenced from the print out, the last entry of every list in \"clean_data\" ends with a quotation mark. However, this issue can be quickly resolving using pandas later. We now continue with our endeavor by pulling what will be our outer index. From the print-out below we see that we need to exclude in our clean list any footnotes, and any extraneous commas or quotations marks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All Races,',\n",
       " 'White Alone 25,',\n",
       " 'White 26,',\n",
       " '\"White Alone, Not Hispanic 25\",',\n",
       " '\"White, Not Hispanic 26\",',\n",
       " 'Black Alone Or In Combination,',\n",
       " 'Black Alone 27,',\n",
       " 'Black 26,',\n",
       " 'Asian Alone Or In Combination,',\n",
       " 'Asian Alone 28,',\n",
       " 'Asian And Pacific Islander 26,',\n",
       " 'American Indian And Alaska Native Alone Or In Combination,',\n",
       " 'American Indian And Alaska Native Alone 29,',\n",
       " 'American Indian And Alaska Native 26,',\n",
       " 'Two Or More Races,',\n",
       " 'Hispanic (Any Race) 30,']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_index_to_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will once again employ re to sort through our outer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All Races',\n",
       " 'White Alone',\n",
       " 'White',\n",
       " 'White Alone Not Hispanic',\n",
       " 'White Not Hispanic',\n",
       " 'Black Alone Or In Combination',\n",
       " 'Black Alone',\n",
       " 'Black',\n",
       " 'Asian Alone Or In Combination',\n",
       " 'Asian Alone',\n",
       " 'Asian And Pacific Islander',\n",
       " 'American Indian And Alaska Native Alone Or In Combination',\n",
       " 'American Indian And Alaska Native Alone',\n",
       " 'American Indian And Alaska Native',\n",
       " 'Two Or More Races',\n",
       " 'Hispanic (Any Race)']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_index_clean = []\n",
    "for k in range(0, len(outer_index_to_clean)):\n",
    "    string_to_clean = outer_index_to_clean[k]\n",
    "    clean_string = ''\n",
    "    for letters in string_to_clean:\n",
    "        if re.findall('[0-9]', letters): # Skip numbers\n",
    "            pass\n",
    "        elif letters == '\\\"': # Skip \"\n",
    "            pass\n",
    "        elif letters == ',': # Skip ,\n",
    "            pass\n",
    "        else:\n",
    "            clean_string = clean_string + letters\n",
    "    clean_string = clean_string.strip()\n",
    "    outer_index_clean.append(clean_string)\n",
    "outer_index_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are interested in matching the length of our outer index and our inner index. Because we will be using pd.Multindex to assemble our table, order and position matter. By conferring with the source CSV file, we first observe that each breakout group in the outer index begins either at year 2021 or year 2001 and extend backwards in time for an irregular period of time. Grouping for the first five breakout groups we find that the first two begin with the year 2021, followed by 2001 twice, and finally the fifth breakout group begins with the year 2021:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_index = []\n",
    "k, l, start = 0, 0, 0 \n",
    "# =====================================================================\n",
    "# k will isolate the breakout group,\n",
    "# l indicates how many times we encounter a target year\n",
    "# start is the begining of each interval begining with the target year\n",
    "#=====================================================================\n",
    "\n",
    "# The first two breakout groups start at 2021\n",
    "for i in range(start, len(inner_index)):\n",
    "    try:\n",
    "        if inner_index[i+1] == '2021': # if the year next in the list is 2021:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "            k += 1 # <-- move on to the next breakout group\n",
    "        elif inner_index[i+1] == '2001':\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "\n",
    "            l += 1\n",
    "            if l == 2: # The second time in the loop that you encounter the year 2001:\n",
    "                start = i + 1 # <-- your next interval to start at\n",
    "                k += 1  # move to the next breakout group\n",
    "                break\n",
    "        else:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# The next break out group begins at 2001\n",
    "for i in range(start, len(inner_index)):\n",
    "    try:\n",
    "        if inner_index[i+1] == '2021': # If the next year is 2021:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "            start = i + 1 # <-- your next interval to start at\n",
    "            k += 1 # <-- move to the next breakout group\n",
    "            break\n",
    "        else:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# The next breakout group begins at 2021\n",
    "for i in range(start, len(inner_index)):\n",
    "    try:\n",
    "        if inner_index[i+1] == '2001': # If the next year is 2001:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "            k += 1 # <-- move to the next breakout group\n",
    "        elif inner_index[i+1] == '2021': # If the next year is 2021:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "            k += 1 # <-- move to the next breakout group\n",
    "            start = i + 1 # <-- your next interval to start at\n",
    "            break\n",
    "        else:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, past the first five breakout groups, the pattern regularizies: we have two breakout groups which begin at the year 2021 followed by one breakout group which begins at the year 2001. To model this behavior we will use modular arithmetic. We need to use two variables: $l \\in \\mathbb{Z}/3\\mathbb{Z}$ to model the pattern $(2021, 2021, 2001)$ and $j \\in \\mathbb{Z}/2\\mathbb{Z}$ to toggle between the two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, j = 2, 0\n",
    "toggle = ['2021', '2001']\n",
    "year = inner_index[start]\n",
    "for i in range(start, len(inner_index)):\n",
    "    try:\n",
    "        if inner_index[i + 1] == year: # If the next year is the target year:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "\n",
    "            k += 1 # <-- move to the next breakout group\n",
    "            l = (l + 1) % 3 # <-- increment our dummy variable\n",
    "\n",
    "            if l == 0 or l == 1: # If 0, 1 = l (mod 3):\n",
    "                j = (j + 1) % 2 \n",
    "                year = toggle[j] # <-- set the next target year\n",
    "        else:\n",
    "            outer_index.append(outer_index_clean[k])\n",
    "\n",
    "    except:\n",
    "        outer_index.append(outer_index_clean[k-1])\n",
    "\n",
    "        \n",
    "# Make sure that the lengths match up!\n",
    "assert len(outer_index) == len(inner_index) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next task is to create arrays of our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total,\"Under $15,000\",\"$15,000 ',\n",
       " 'to',\n",
       " ' $24,999\",\"$25,000 ',\n",
       " 'to',\n",
       " ' $34,999\",\"$35,000 ',\n",
       " 'to',\n",
       " ' $49,999\",\"$50,000 ',\n",
       " 'to',\n",
       " ' $74,999\",\"$75,000 ',\n",
       " 'to',\n",
       " ' $99,999\",\"$100,000 ',\n",
       " 'to',\n",
       " ' $149,999\",\"$150,000 ',\n",
       " 'to',\n",
       " ' $199,999\",\"$200,000 and over\",Estimate,Margin of error1 (Â±),Estimate,Margin of error1 (Â±)']"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_column_level2 = to_clean[8:23]\n",
    "dirty_column_level2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean these columns we will first convert this list into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_string = ''\n",
    "for strings in dirty_column_level2:\n",
    "    dirty_string = dirty_string + strings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use re to launder our dirty string into a usable array of columns. Before proceeding, one column has been ommitted in the information gathered, \"Number (Thousands).\" Using our variable \"final_wash,\" we will recover this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Number (Thousands)', 'Total', 'Under $15000', '$15000 to $24999',\n",
       "       '$25000 to $34999', '$35000 to $49999', '$50000 to $74999',\n",
       "       '$75000 to $99999', '$100000 to $149999', '$150000 to $199999',\n",
       "       '$200000 and over', 'Estimate', 'Margin of error', 'Estimate',\n",
       "       'Margin of error'], dtype='<U18')"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_wash = 'Number (Thousands),'\n",
    "for k in range(0, len(dirty_string)):\n",
    "    try:\n",
    "        if re.findall('[0-9],[0-9]', dirty_string[k-1] + dirty_string[k] + dirty_string[k+1]): # If you're string wedged between two numbers: Pass\n",
    "            pass\n",
    "        elif re.findall('\\\"|\\(|\\)|Â|±', dirty_string[k]): # If you're a strange character: Pass\n",
    "            pass\n",
    "        elif re.findall('r1', dirty_string[k-1] + dirty_string[k]): # If the string behind you is an r: Pass\n",
    "            pass\n",
    "        elif re.findall('1 ', dirty_string[k-1] + dirty_string[k]): # If the string behind you is a one: Pass\n",
    "            pass\n",
    "        else:\n",
    "            final_wash = final_wash + dirty_string[k]\n",
    "    except:\n",
    "        pass\n",
    "column_level2 = final_wash.split(',') # Split the string by a comma\n",
    "column_level2 = np.array(column_level2) # Convert your list into a numpy array\n",
    "column_level2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will produce the first level of columns by hard-coding them in. If this dataset were larger, there may be quicker methods. We first observe that in the source CSV we have four columns: Number (Thousands), Percent Distribution, Median Income, and Mean Income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = 'Number (Thousands),'\n",
    "a2 = 'Percent Distribution,'\n",
    "a3 = 'Median Income,'\n",
    "a4 = 'Mean Income,'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use some fun string arithmetic to match the length of the columns in the level beneath it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_level1 = (a0 + (a2 * 10) + (a3 * 2) + (a4 * 2)).split(',')[0:-1] # The last entry is an empty string\n",
    "column_level1 = np.array(column_level1) # Convert this column into a numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have gathered all of our indicies and columns, we must now put them into a list which we can then use to create our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_arrays = [column_level1, column_level2]\n",
    "index_arrays = [np.array(outer_index), np.array(inner_index)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clean_data, index=index_arrays, columns=column_arrays)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our final cleaning step is to erase every quotation mark in our last column and convert each value to a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Number (Thousands)</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Percent Distribution</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Median Income</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Mean Income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Number (Thousands)</th>\n",
       "      <th>Total</th>\n",
       "      <th>Under $15000</th>\n",
       "      <th>$15000 to $24999</th>\n",
       "      <th>$25000 to $34999</th>\n",
       "      <th>$35000 to $49999</th>\n",
       "      <th>$50000 to $74999</th>\n",
       "      <th>$75000 to $99999</th>\n",
       "      <th>$100000 to $149999</th>\n",
       "      <th>$150000 to $199999</th>\n",
       "      <th>$200000 and over</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Margin of error</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Margin of error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">All Races</th>\n",
       "      <th>2021</th>\n",
       "      <td>131202.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.6</td>\n",
       "      <td>70784.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>102316.0</td>\n",
       "      <td>1029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>129244.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>71186.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>102020.0</td>\n",
       "      <td>1098.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>128451.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>16.1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>72808.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>103949.0</td>\n",
       "      <td>1104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>128579.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>68168.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>97129.0</td>\n",
       "      <td>969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>127669.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10.1</td>\n",
       "      <td>67571.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>96868.0</td>\n",
       "      <td>1037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Hispanic (Any Race)</th>\n",
       "      <th>1976</th>\n",
       "      <td>3081.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>20.3</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>41545.0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>49096.0</td>\n",
       "      <td>1314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>2948.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>40704.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>48321.0</td>\n",
       "      <td>1412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2897.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>44253.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>51264.0</td>\n",
       "      <td>1373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>2722.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>22.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>44513.0</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>51717.0</td>\n",
       "      <td>1385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>2655.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>23.7</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>44587.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>51249.0</td>\n",
       "      <td>1433.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Number (Thousands) Percent Distribution               \\\n",
       "                         Number (Thousands)                Total Under $15000   \n",
       "All Races           2021           131202.0                100.0          9.3   \n",
       "                    2020           129244.0                100.0          8.8   \n",
       "                    2019           128451.0                100.0          8.5   \n",
       "                    2018           128579.0                100.0          9.4   \n",
       "                    2017           127669.0                100.0          9.4   \n",
       "...                                     ...                  ...          ...   \n",
       "Hispanic (Any Race) 1976             3081.0                100.0         14.7   \n",
       "                    1975             2948.0                100.0         14.7   \n",
       "                    1974             2897.0                100.0         11.9   \n",
       "                    1973             2722.0                100.0         11.1   \n",
       "                    1972             2655.0                100.0         10.8   \n",
       "\n",
       "                                                                             \\\n",
       "                         $15000 to $24999 $25000 to $34999 $35000 to $49999   \n",
       "All Races           2021              8.1              7.8             10.9   \n",
       "                    2020              8.2              8.1             11.0   \n",
       "                    2019              7.5              8.0             11.3   \n",
       "                    2018              8.3              8.4             11.5   \n",
       "                    2017              8.6              8.6             11.8   \n",
       "...                                   ...              ...              ...   \n",
       "Hispanic (Any Race) 1976             14.2             13.6             17.2   \n",
       "                    1975             14.4             14.3             17.6   \n",
       "                    1974             14.2             13.5             18.2   \n",
       "                    1973             13.1             13.7             18.4   \n",
       "                    1972             14.7             13.3             19.6   \n",
       "\n",
       "                                                                               \\\n",
       "                         $50000 to $74999 $75000 to $99999 $100000 to $149999   \n",
       "All Races           2021             16.2             11.9               15.9   \n",
       "                    2020             16.2             12.3               15.8   \n",
       "                    2019             16.1             12.1               16.3   \n",
       "                    2018             16.4             12.8               15.6   \n",
       "                    2017             15.8             12.6               15.2   \n",
       "...                                   ...              ...                ...   \n",
       "Hispanic (Any Race) 1976             20.3             11.6                6.2   \n",
       "                    1975             21.4             10.3                5.7   \n",
       "                    1974             22.1             11.3                6.9   \n",
       "                    1973             22.4             12.6                6.9   \n",
       "                    1972             23.7             10.1                6.1   \n",
       "\n",
       "                                                             Median Income  \\\n",
       "                         $150000 to $199999 $200000 and over      Estimate   \n",
       "All Races           2021                8.3             11.6       70784.0   \n",
       "                    2020                8.4             11.3       71186.0   \n",
       "                    2019                8.7             11.5       72808.0   \n",
       "                    2018                7.9              9.8       68168.0   \n",
       "                    2017                7.7             10.1       67571.0   \n",
       "...                                     ...              ...           ...   \n",
       "Hispanic (Any Race) 1976                1.7              0.4       41545.0   \n",
       "                    1975                1.0              0.7       40704.0   \n",
       "                    1974                1.3              0.7       44253.0   \n",
       "                    1973                1.3              0.5       44513.0   \n",
       "                    1972                1.1              0.8       44587.0   \n",
       "\n",
       "                                         Mean Income                  \n",
       "                         Margin of error    Estimate Margin of error  \n",
       "All Races           2021           605.0    102316.0          1029.0  \n",
       "                    2020           921.0    102020.0          1098.0  \n",
       "                    2019           959.0    103949.0          1104.0  \n",
       "                    2018           746.0     97129.0           969.0  \n",
       "                    2017           585.0     96868.0          1037.0  \n",
       "...                                  ...         ...             ...  \n",
       "Hispanic (Any Race) 1976          1457.0     49096.0          1314.0  \n",
       "                    1975          1480.0     48321.0          1412.0  \n",
       "                    1974          1594.0     51264.0          1373.0  \n",
       "                    1973          1663.0     51717.0          1385.0  \n",
       "                    1972          1433.0     51249.0          1433.0  \n",
       "\n",
       "[437 rows x 15 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace('\\\"', \"\", inplace=True, regex=True)\n",
    "df = df.astype(float)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will save this dataframe as both a pickle and a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clean-csv/table-A2.csv\")\n",
    "df.to_pickle(\"clean-pickle/table-A2.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='taba2'></a><h2 style='text-align: center'>Educational Attainment of People 25 Years and Over: Selected Years 1940 to 2021 </h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we import numpy, pandas, and re."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import our data we begin by reading in the CSV. As we read in each line of the CSV we will use re to seperate lines which contain numeric and non numeric data. As well, before each line of data is appended to its list, we will replace the superfluous characters \",,\" and \"\\n.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "breakout_groups = []\n",
    "years = []\n",
    "outer_index_to_clean = []\n",
    "\n",
    "with open(r\"data-capstone/taba-2.csv\") as f:\n",
    "    for lines in f:\n",
    "        if re.findall('[a-z]', lines): # If the element contains a lower-case letter:\n",
    "            breakout_groups.append(lines.replace(',,', '').replace('\\n', '')) # <-- append it to the breakout groups\n",
    "        if re.findall('[1-9],[1-9]', lines): # If the element contains a comma between two numbers:\n",
    "            data.append(lines.replace(',,', '').replace('\\n', '')) # <-- append it to data\n",
    "        if re.findall('[0-9][0-9] [A-Z]', lines): # If the element contains two numbers followed by a space and an upper-case letter:\n",
    "            outer_index_to_clean.append(lines.replace(',,', '').replace('\\n', '')) # <-- append it to the outer-index list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will construct our first column level. In examining the source CSV file, we find that each column in the first level repeats three times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['All races', 'All races', 'All races', 'White', 'White', 'White',\n",
       "       'Non-Hispanic White', 'Non-Hispanic White', 'Non-Hispanic White',\n",
       "       'Black', 'Black', 'Black', 'Asian', 'Asian', 'Asian', '\"Hispanic ',\n",
       "       '\"Hispanic ', '\"Hispanic ', 'White alone or in combination',\n",
       "       'White alone or in combination', 'White alone or in combination',\n",
       "       'Non-Hispanic White alone or in combination',\n",
       "       'Non-Hispanic White alone or in combination',\n",
       "       'Non-Hispanic White alone or in combination',\n",
       "       'Black alone or in combination', 'Black alone or in combination',\n",
       "       'Black alone or in combination', 'Asian alone or in combination',\n",
       "       'Asian alone or in combination', 'Asian alone or in combination'],\n",
       "      dtype='<U42')"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_clean = breakout_groups[3].split(',') # This is where most of our first column level lives\n",
    "to_clean = to_clean[1:] # The 0th entry is irrelevant\n",
    "\n",
    "column_level1 = []\n",
    "for i in range(0, len(to_clean)):\n",
    "    # Append each header three times \n",
    "    column_level1.append(to_clean[i])\n",
    "    column_level1.append(to_clean[i])\n",
    "    column_level1.append(to_clean[i])\n",
    "\n",
    "# We'll now retrieve the other column headers for this level\n",
    "other_bit = breakout_groups[4].split(',')[1:-1]\n",
    "for i in range(0, len(other_bit)):\n",
    "    # Append each header three times\n",
    "    column_level1.append(other_bit[i])\n",
    "    column_level1.append(other_bit[i])\n",
    "    column_level1.append(other_bit[i])\n",
    "\n",
    "column_level1 = np.array(column_level1) # Convert this level into a numpy array\n",
    "column_level1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now assemble the second column level which is nearly intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Total', 'Male', 'Female', 'Total', 'Male', 'Female', 'Total',\n",
       "       'Male', 'Female', 'Total', 'Male', 'Female', 'Total', 'Male',\n",
       "       'Female', 'Total', 'Male', 'Female', 'Total', 'Male', 'Female',\n",
       "       'Total', 'Male', 'Female', 'Total', 'Male', 'Female', 'Total',\n",
       "       'Male', 'Female'], dtype='<U6')"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_level2 = breakout_groups[5].split(',')[1:-1]\n",
    "column_level2 = np.array(column_level2) # Convert to a numpy array\n",
    "column_level2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will grab the inner index and the raw data for each row in the table. The data was very well preserved and the only cleaning needed to be done was to replace each \"(NA)\" with np.nan and to each row entry with its corresponding year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90.9',\n",
       " '90.6',\n",
       " '91.3',\n",
       " '91.3',\n",
       " '90.8',\n",
       " '91.7',\n",
       " '95.1',\n",
       " '94.8',\n",
       " '95.4',\n",
       " '89.4',\n",
       " '88.6',\n",
       " '90.0',\n",
       " '91.6',\n",
       " '92.6',\n",
       " '90.7',\n",
       " '74.3',\n",
       " '73.8',\n",
       " '74.8',\n",
       " '91.2',\n",
       " '90.8',\n",
       " '91.6',\n",
       " '95.1',\n",
       " '94.8',\n",
       " '95.4',\n",
       " '89.5',\n",
       " '88.8',\n",
       " '90.1',\n",
       " '91.7',\n",
       " '92.7',\n",
       " '90.9']"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_index = []\n",
    "clean_data = []\n",
    "for k in range(0, len(data)):\n",
    "    raw_data = []\n",
    "    dirty_data = data[k].split(',')\n",
    "    for i in range(0, len(dirty_data)): \n",
    "        if re.findall('\\(NA\\)', dirty_data[i]): # If the element looks like (NA):\n",
    "            raw_data.append(np.nan) # Replace it with np.nan\n",
    "        elif dirty_data[i] == '': # If you're a blank element: Pass\n",
    "            pass\n",
    "        else:\n",
    "            raw_data.append(dirty_data[i])\n",
    "    inner_index.append(raw_data[0]) # The year is the first entry in the raw_data list\n",
    "    raw_data = raw_data[1:]\n",
    "    clean_data.append(raw_data)\n",
    "# The first entry in clean_data\n",
    "clean_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will grab the core elements of the outer index by slicing our outer_index_to_clean list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25 Years And Older', '25 To 29 Years']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_clean = outer_index_to_clean[1:3]\n",
    "outer_index_to_extend = []\n",
    "for items in to_clean:\n",
    "    outer_index_to_extend.append(items.replace(',', '').title())\n",
    "outer_index_to_extend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we slice our breakout_groups list to isolate all of our core middile index items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Completed 4 Years Of High School Or More',\n",
       " 'Completed 4 Years Of College Or More',\n",
       " 'Completed 4 Years Of High School Or More',\n",
       " 'Completed 4 Years Of College Or More']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_clean = breakout_groups[6:10]\n",
    "middle_index_to_extend = []\n",
    "for items in to_clean:\n",
    "    middle_index_to_extend.append(items.replace(',', '').title())\n",
    "middle_index_to_extend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now employ modular arithmetic to model the behavior of these indicies. Conferring with the source CSV we see that each element in the outer index cycles through the two unique middle index values and is periodic with respect to the inner index value 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_index = []\n",
    "outer_index = []\n",
    "i, j = 0, 0\n",
    "for k in range(0, len(inner_index)):\n",
    "    try:\n",
    "        if inner_index[k + 1] == '2020': # If the next year is 2020:\n",
    "            middle_index.append(middle_index_to_extend[i])\n",
    "            outer_index.append(outer_index_to_extend[j])\n",
    "            i += 1 # <-- move to the next element in the middle index list\n",
    "            if i % 2 == 0: # <-- if you've visited the year 2019 twice:\n",
    "                j += 1 # Move to the next element in the outer index list\n",
    "        else:\n",
    "            middle_index.append(middle_index_to_extend[i])\n",
    "            outer_index.append(outer_index_to_extend[j])\n",
    "    except:\n",
    "        middle_index.append(middle_index_to_extend[i])\n",
    "        outer_index.append(outer_index_to_extend[j])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of our column and index levels are accounted for, we will now put together a list of our column and index arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_arrays = [column_level1, column_level2]\n",
    "index_arrays = [np.array(outer_index), np.array(middle_index), np.array(inner_index)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assemble the dataframe and convert all numeric data to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clean_data, index=index_arrays, columns=column_arrays)\n",
    "df = df.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five rows of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">All races</th>\n",
       "      <th colspan=\"3\" halign=\"left\">White</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Non-Hispanic White</th>\n",
       "      <th>Black</th>\n",
       "      <th>...</th>\n",
       "      <th>White alone or in combination</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Non-Hispanic White alone or in combination</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Black alone or in combination</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Asian alone or in combination</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Total</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Total</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Total</th>\n",
       "      <th>...</th>\n",
       "      <th>Female</th>\n",
       "      <th>Total</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Total</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Total</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">25 Years And Older</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Completed 4 Years Of High School Or More</th>\n",
       "      <th>2020</th>\n",
       "      <td>90.9</td>\n",
       "      <td>90.6</td>\n",
       "      <td>91.3</td>\n",
       "      <td>91.3</td>\n",
       "      <td>90.8</td>\n",
       "      <td>91.7</td>\n",
       "      <td>95.1</td>\n",
       "      <td>94.8</td>\n",
       "      <td>95.4</td>\n",
       "      <td>89.4</td>\n",
       "      <td>...</td>\n",
       "      <td>91.6</td>\n",
       "      <td>95.1</td>\n",
       "      <td>94.8</td>\n",
       "      <td>95.4</td>\n",
       "      <td>89.5</td>\n",
       "      <td>88.8</td>\n",
       "      <td>90.1</td>\n",
       "      <td>91.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>90.1</td>\n",
       "      <td>89.6</td>\n",
       "      <td>90.5</td>\n",
       "      <td>90.5</td>\n",
       "      <td>89.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>94.2</td>\n",
       "      <td>95.0</td>\n",
       "      <td>87.9</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>94.2</td>\n",
       "      <td>94.9</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.1</td>\n",
       "      <td>88.8</td>\n",
       "      <td>91.5</td>\n",
       "      <td>92.9</td>\n",
       "      <td>90.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>89.8</td>\n",
       "      <td>89.4</td>\n",
       "      <td>90.2</td>\n",
       "      <td>90.2</td>\n",
       "      <td>89.6</td>\n",
       "      <td>90.8</td>\n",
       "      <td>94.3</td>\n",
       "      <td>93.9</td>\n",
       "      <td>94.7</td>\n",
       "      <td>87.9</td>\n",
       "      <td>...</td>\n",
       "      <td>90.7</td>\n",
       "      <td>94.3</td>\n",
       "      <td>93.9</td>\n",
       "      <td>94.6</td>\n",
       "      <td>87.9</td>\n",
       "      <td>87.6</td>\n",
       "      <td>88.2</td>\n",
       "      <td>90.7</td>\n",
       "      <td>92.9</td>\n",
       "      <td>88.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>89.6</td>\n",
       "      <td>89.1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>89.5</td>\n",
       "      <td>90.6</td>\n",
       "      <td>94.1</td>\n",
       "      <td>93.7</td>\n",
       "      <td>94.5</td>\n",
       "      <td>87.3</td>\n",
       "      <td>...</td>\n",
       "      <td>90.5</td>\n",
       "      <td>94.1</td>\n",
       "      <td>93.7</td>\n",
       "      <td>94.5</td>\n",
       "      <td>87.2</td>\n",
       "      <td>86.3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>91.1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>89.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>89.1</td>\n",
       "      <td>88.5</td>\n",
       "      <td>89.6</td>\n",
       "      <td>89.5</td>\n",
       "      <td>88.8</td>\n",
       "      <td>90.1</td>\n",
       "      <td>93.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>94.3</td>\n",
       "      <td>87.1</td>\n",
       "      <td>...</td>\n",
       "      <td>90.1</td>\n",
       "      <td>93.8</td>\n",
       "      <td>93.4</td>\n",
       "      <td>94.3</td>\n",
       "      <td>87.2</td>\n",
       "      <td>86.5</td>\n",
       "      <td>87.7</td>\n",
       "      <td>90.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>89.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 All races  \\\n",
       "                                                                     Total   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020      90.9   \n",
       "                                                            2019      90.1   \n",
       "                                                            2018      89.8   \n",
       "                                                            2017      89.6   \n",
       "                                                            2016      89.1   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                  Male Female   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020  90.6   91.3   \n",
       "                                                            2019  89.6   90.5   \n",
       "                                                            2018  89.4   90.2   \n",
       "                                                            2017  89.1   90.0   \n",
       "                                                            2016  88.5   89.6   \n",
       "\n",
       "                                                                 White        \\\n",
       "                                                                 Total  Male   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020  91.3  90.8   \n",
       "                                                            2019  90.5  89.9   \n",
       "                                                            2018  90.2  89.6   \n",
       "                                                            2017  90.1  89.5   \n",
       "                                                            2016  89.5  88.8   \n",
       "\n",
       "                                                                         \\\n",
       "                                                                 Female   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020   91.7   \n",
       "                                                            2019   91.0   \n",
       "                                                            2018   90.8   \n",
       "                                                            2017   90.6   \n",
       "                                                            2016   90.1   \n",
       "\n",
       "                                                                 Non-Hispanic White  \\\n",
       "                                                                              Total   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020               95.1   \n",
       "                                                            2019               94.6   \n",
       "                                                            2018               94.3   \n",
       "                                                            2017               94.1   \n",
       "                                                            2016               93.8   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                  Male Female   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020  94.8   95.4   \n",
       "                                                            2019  94.2   95.0   \n",
       "                                                            2018  93.9   94.7   \n",
       "                                                            2017  93.7   94.5   \n",
       "                                                            2016  93.4   94.3   \n",
       "\n",
       "                                                                 Black  ...  \\\n",
       "                                                                 Total  ...   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020  89.4  ...   \n",
       "                                                            2019  87.9  ...   \n",
       "                                                            2018  87.9  ...   \n",
       "                                                            2017  87.3  ...   \n",
       "                                                            2016  87.1  ...   \n",
       "\n",
       "                                                                 White alone or in combination  \\\n",
       "                                                                                        Female   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020                          91.6   \n",
       "                                                            2019                          91.0   \n",
       "                                                            2018                          90.7   \n",
       "                                                            2017                          90.5   \n",
       "                                                            2016                          90.1   \n",
       "\n",
       "                                                                 Non-Hispanic White alone or in combination  \\\n",
       "                                                                                                      Total   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020                                       95.1   \n",
       "                                                            2019                                       94.6   \n",
       "                                                            2018                                       94.3   \n",
       "                                                            2017                                       94.1   \n",
       "                                                            2016                                       93.8   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                  Male Female   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020  94.8   95.4   \n",
       "                                                            2019  94.2   94.9   \n",
       "                                                            2018  93.9   94.6   \n",
       "                                                            2017  93.7   94.5   \n",
       "                                                            2016  93.4   94.3   \n",
       "\n",
       "                                                                 Black alone or in combination  \\\n",
       "                                                                                         Total   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020                          89.5   \n",
       "                                                            2019                          88.0   \n",
       "                                                            2018                          87.9   \n",
       "                                                            2017                          87.2   \n",
       "                                                            2016                          87.2   \n",
       "\n",
       "                                                                               \\\n",
       "                                                                  Male Female   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020  88.8   90.1   \n",
       "                                                            2019  87.1   88.8   \n",
       "                                                            2018  87.6   88.2   \n",
       "                                                            2017  86.3   88.0   \n",
       "                                                            2016  86.5   87.7   \n",
       "\n",
       "                                                                 Asian alone or in combination  \\\n",
       "                                                                                         Total   \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020                          91.7   \n",
       "                                                            2019                          91.5   \n",
       "                                                            2018                          90.7   \n",
       "                                                            2017                          91.1   \n",
       "                                                            2016                          90.6   \n",
       "\n",
       "                                                                               \n",
       "                                                                  Male Female  \n",
       "25 Years And Older Completed 4 Years Of High School Or More 2020  92.7   90.9  \n",
       "                                                            2019  92.9   90.1  \n",
       "                                                            2018  92.9   88.8  \n",
       "                                                            2017  92.7   89.7  \n",
       "                                                            2016  92.0   89.4  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our dataframe to CSV and pickle it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean-csv/taba-2.csv')\n",
    "df.to_pickle('clean-pickle/taba-2.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='taba3'></a><h2 style='text-align: center'>Mean Earnings of Workers 18 Years and Over: 1975 to 2020</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin, as usual, with loading the required packages. In this case we will be using numpy, pandas, and re."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will reading the data which was downloaded in as a CSV. Simultaneously, as we read in the lines from the CSV we will be filtering out lines which contain numeric and text data into two sperate lists to clean. As well, before each element is added to the list, we will be replacing the characters ',,' and '\\n' which are artifacts from the CSV irrelevant to our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "breakout_groups = []\n",
    "years = []\n",
    "to_match = '[a-z]'\n",
    "\n",
    "with open(r\"data-capstone/taba-3.csv\") as f:\n",
    "    for lines in f:\n",
    "        if re.findall(to_match, lines):\n",
    "            breakout_groups.append(lines.replace(',,', '').replace('\\n', ''))\n",
    "        if re.findall('[1-9],[1-9]', lines):\n",
    "            data.append(lines.replace(',,', '').replace('\\n', ''))\n",
    "\n",
    "breakout_groups = breakout_groups[0:45] # Elements past index 45 contain footnote information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beacuase of the multi-level style of CSV imported, to keep that structure intact, we will be using a multi-index within pandas. As such, it will be necessary to capture the appropriate length of the number of columns in are resulting data frame. In this case, we have eighteen columns and six different breakout groups so we will append each item three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total',\n",
       " 'Total',\n",
       " 'Total',\n",
       " 'Not a high school graduate',\n",
       " 'Not a high school graduate',\n",
       " 'Not a high school graduate',\n",
       " 'High school graduate',\n",
       " 'High school graduate',\n",
       " 'High school graduate',\n",
       " \"Some college/associate's degree\",\n",
       " \"Some college/associate's degree\",\n",
       " \"Some college/associate's degree\",\n",
       " \"Bachelor's degree\",\n",
       " \"Bachelor's degree\",\n",
       " \"Bachelor's degree\",\n",
       " 'Advanced degree',\n",
       " 'Advanced degree',\n",
       " 'Advanced degree']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_split = breakout_groups[3].split(',')\n",
    "column_level1 = []\n",
    "for i in range(3, len(to_split)):\n",
    "    column_level1.append(to_split[i])\n",
    "    column_level1.append(to_split[i])\n",
    "    column_level1.append(to_split[i])\n",
    "column_level1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will construct the second column level in a similar fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mean',\n",
       " 'Number with earnings',\n",
       " 'Standard error',\n",
       " 'Mean',\n",
       " 'Number with earnings',\n",
       " 'Standard error',\n",
       " 'Mean',\n",
       " 'Number with earnings',\n",
       " 'Standard error',\n",
       " 'Mean',\n",
       " 'Number with earnings',\n",
       " 'Standard error',\n",
       " 'Mean',\n",
       " 'Number with earnings',\n",
       " 'Standard error',\n",
       " 'Mean',\n",
       " 'Number with earnings',\n",
       " 'Standard error']"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_level2 = []\n",
    "to_split = breakout_groups[4].split(',')\n",
    "to_split.remove('')\n",
    "for items in to_split:\n",
    "    column_level2.append(items)\n",
    "column_level2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have pulled apart each column level, we can begin cleaning the data and isolating each index. In this dataset we will have three indicies: race, gender, and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pull the years out of the unclean data\n",
    "years = [i for i in range(1975, 2020)]\n",
    "condition = ''\n",
    "for i in years:\n",
    "    condition = condition + str(i) + '|'\n",
    "\n",
    "\n",
    "raw_data = []\n",
    "inner_index = [] # This will contain the year\n",
    "for i in range(0, len(data)):\n",
    "    to_clean = []\n",
    "    year = []\n",
    "    to_filter = re.findall('\"[^\"]*\"|,[0-9][0-9][0-9]', data[i]) # We want to grab everything between the quotation marks\n",
    "    year.append(re.findall(condition, data[i])[0])\n",
    "    for items in to_filter:\n",
    "        to_clean.append(items.replace(',', '').replace('\\\"', '')) # Now we will replace each comma with nothing to convert the data to float later\n",
    "    raw_data.append(to_clean) # Append the clean data\n",
    "    inner_index.append(year[0]) # Append the year to the inner index list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully filtered out the inner index and raw data, we will turn our attention to the middle and outer indicies. For each item in our initial breakout groups list, we can find our outer index at list indicies, $i$, where $$i \\in 1 + 4 \\mathbb{Z}.$$ As well we find that our middle indicies are located at list index, $j$, where $$j \\in \\{ \\mathbb{Z}/4\\mathbb{Z} - \\{1 + 4\\mathbb{Z}\\}  \\}.$$ We also observe that for each index in the source CSV file that, although each breakout group has a variable number of years included in the dataset, the year data is periodic with respect to the year 2019. This means that if we know that the next item in our inner index list is 2019 our break out group needs to change. Keeping in mind that becuase we will be using a multi-index for the resulting pandas dataframe, meaning that length and position matter, in light of both of these observations, we can now construct a for loop which will append items to a middle index and outer index list corresponding to their breakout group index value modulo four which will shift values when the next year added is 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_index = []\n",
    "outer_index = []\n",
    "\n",
    "i, j, l = 1, 1, 0\n",
    "for k in range(0, len(inner_index)):\n",
    "    try:\n",
    "        if inner_index[k + 1] != '2019':\n",
    "            middle_index.append(breakout_groups[(4 * i) + 1 + j].replace(',', '')) # Our middle indicies appear at 0, 2, 3 (mod 4)\n",
    "            outer_index.append(breakout_groups[(4 * i) + 1]) # Our outer indicies appear at index valued 1 (mod4)\n",
    "        else:\n",
    "            middle_index.append(breakout_groups[(4 * i) + 1 + j].replace(',', ''))\n",
    "            outer_index.append(breakout_groups[(4 * i) + 1])\n",
    "            l = (1 + l) % 3 # We have three middle indicies to grab: Both Sexes, Male, Female\n",
    "            j = (1 + j) % 4 # Each middle index appears three times per outer index\n",
    "            if l == 0: # When we've captured all three middle indicies we increment our outer index value by one\n",
    "                i += 1\n",
    "            if j == 0: # if j == 0 then we would accidentally append our outer index to the wrong list!\n",
    "                j += 1\n",
    "                \n",
    "    except:\n",
    "        middle_index.append(breakout_groups[(4 * i) + 1 + j].replace(',', ''))\n",
    "        outer_index.append(breakout_groups[(4 * i) + 1])\n",
    "        pass\n",
    "    \n",
    "assert len(inner_index) == len(middle_index) ==len(outer_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have captured all of the necessary data, to make use of pandas multi-index we will now create a list of column and index arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_arrays = [np.array(column_level1), np.array(column_level2)]\n",
    "index_arrays = [np.array(outer_index), np.array(middle_index), np.array(inner_index)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to compile the dataframe. After doing so, our final cleaning step is to convert our numeric data to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(raw_data, index=index_arrays, columns=column_arrays)\n",
    "df = df.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five rows of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Total</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Not a high school graduate</th>\n",
       "      <th colspan=\"3\" halign=\"left\">High school graduate</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Some college/associate's degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Bachelor's degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Advanced degree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Total</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Both Sexes</th>\n",
       "      <th>2019</th>\n",
       "      <td>58544.0</td>\n",
       "      <td>167215.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>29278.0</td>\n",
       "      <td>11413.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>39371.0</td>\n",
       "      <td>42598.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>45091.0</td>\n",
       "      <td>46885.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>73163.0</td>\n",
       "      <td>42153.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>106766.0</td>\n",
       "      <td>24164.0</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>55619.0</td>\n",
       "      <td>165179.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>27037.0</td>\n",
       "      <td>12058.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>38936.0</td>\n",
       "      <td>42882.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>43053.0</td>\n",
       "      <td>46887.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>71155.0</td>\n",
       "      <td>40231.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>99919.0</td>\n",
       "      <td>23118.0</td>\n",
       "      <td>1186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>53536.0</td>\n",
       "      <td>163871.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>26832.0</td>\n",
       "      <td>12240.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>38145.0</td>\n",
       "      <td>42816.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>41507.0</td>\n",
       "      <td>47382.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>67763.0</td>\n",
       "      <td>39153.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>98369.0</td>\n",
       "      <td>22277.0</td>\n",
       "      <td>933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51893.0</td>\n",
       "      <td>162218.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>27800.0</td>\n",
       "      <td>12281.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>36702.0</td>\n",
       "      <td>42897.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>40201.0</td>\n",
       "      <td>48128.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>67267.0</td>\n",
       "      <td>37272.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>95203.0</td>\n",
       "      <td>21639.0</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>49994.0</td>\n",
       "      <td>161074.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>25315.0</td>\n",
       "      <td>13159.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>35615.0</td>\n",
       "      <td>42404.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>38943.0</td>\n",
       "      <td>47961.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>65482.0</td>\n",
       "      <td>36348.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>92525.0</td>\n",
       "      <td>21199.0</td>\n",
       "      <td>898.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Total                                      \\\n",
       "                          Mean Number with earnings Standard error   \n",
       "Total Both Sexes 2019  58544.0             167215.0          329.0   \n",
       "                 2018  55619.0             165179.0          296.0   \n",
       "                 2017  53536.0             163871.0          218.0   \n",
       "                 2016  51893.0             162218.0          217.0   \n",
       "                 2015  49994.0             161074.0          209.0   \n",
       "\n",
       "                      Not a high school graduate                       \\\n",
       "                                            Mean Number with earnings   \n",
       "Total Both Sexes 2019                    29278.0              11413.0   \n",
       "                 2018                    27037.0              12058.0   \n",
       "                 2017                    26832.0              12240.0   \n",
       "                 2016                    27800.0              12281.0   \n",
       "                 2015                    25315.0              13159.0   \n",
       "\n",
       "                                     High school graduate  \\\n",
       "                      Standard error                 Mean   \n",
       "Total Both Sexes 2019          552.0              39371.0   \n",
       "                 2018          481.0              38936.0   \n",
       "                 2017          383.0              38145.0   \n",
       "                 2016          559.0              36702.0   \n",
       "                 2015          422.0              35615.0   \n",
       "\n",
       "                                                           \\\n",
       "                      Number with earnings Standard error   \n",
       "Total Both Sexes 2019              42598.0          329.0   \n",
       "                 2018              42882.0          376.0   \n",
       "                 2017              42816.0          320.0   \n",
       "                 2016              42897.0          296.0   \n",
       "                 2015              42404.0          271.0   \n",
       "\n",
       "                      Some college/associate's degree                       \\\n",
       "                                                 Mean Number with earnings   \n",
       "Total Both Sexes 2019                         45091.0              46885.0   \n",
       "                 2018                         43053.0              46887.0   \n",
       "                 2017                         41507.0              47382.0   \n",
       "                 2016                         40201.0              48128.0   \n",
       "                 2015                         38943.0              47961.0   \n",
       "\n",
       "                                     Bachelor's degree                       \\\n",
       "                      Standard error              Mean Number with earnings   \n",
       "Total Both Sexes 2019          411.0           73163.0              42153.0   \n",
       "                 2018          416.0           71155.0              40231.0   \n",
       "                 2017          291.0           67763.0              39153.0   \n",
       "                 2016          277.0           67267.0              37272.0   \n",
       "                 2015          261.0           65482.0              36348.0   \n",
       "\n",
       "                                     Advanced degree                       \\\n",
       "                      Standard error            Mean Number with earnings   \n",
       "Total Both Sexes 2019          719.0        106766.0              24164.0   \n",
       "                 2018          676.0         99919.0              23118.0   \n",
       "                 2017          462.0         98369.0              22277.0   \n",
       "                 2016          508.0         95203.0              21639.0   \n",
       "                 2015          516.0         92525.0              21199.0   \n",
       "\n",
       "                                      \n",
       "                      Standard error  \n",
       "Total Both Sexes 2019         1440.0  \n",
       "                 2018         1186.0  \n",
       "                 2017          933.0  \n",
       "                 2016          909.0  \n",
       "                 2015          898.0  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will pickle our dataset and save it as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean-csv/taba-3.csv')\n",
    "df.to_pickle('clean-pickle/taba-3.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='howto'></a><h2 style='text-align:center'>Recovering Dataframes</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover any one of these dataframes, I would recommend either un pickling the dataframe or using optional arguments in the pd.read_csv function to preserve the intended structure. For example, to recover the \"Mean Earnings of Workers 18 Years and Over: 1975 to 2020\" dataframe, one could use pd.read_pickle to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Total</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Not a high school graduate</th>\n",
       "      <th colspan=\"3\" halign=\"left\">High school graduate</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Some college/associate's degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Bachelor's degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Advanced degree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Total</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Both Sexes</th>\n",
       "      <th>2019</th>\n",
       "      <td>58544.0</td>\n",
       "      <td>167215.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>29278.0</td>\n",
       "      <td>11413.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>39371.0</td>\n",
       "      <td>42598.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>45091.0</td>\n",
       "      <td>46885.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>73163.0</td>\n",
       "      <td>42153.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>106766.0</td>\n",
       "      <td>24164.0</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>55619.0</td>\n",
       "      <td>165179.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>27037.0</td>\n",
       "      <td>12058.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>38936.0</td>\n",
       "      <td>42882.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>43053.0</td>\n",
       "      <td>46887.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>71155.0</td>\n",
       "      <td>40231.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>99919.0</td>\n",
       "      <td>23118.0</td>\n",
       "      <td>1186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>53536.0</td>\n",
       "      <td>163871.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>26832.0</td>\n",
       "      <td>12240.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>38145.0</td>\n",
       "      <td>42816.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>41507.0</td>\n",
       "      <td>47382.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>67763.0</td>\n",
       "      <td>39153.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>98369.0</td>\n",
       "      <td>22277.0</td>\n",
       "      <td>933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51893.0</td>\n",
       "      <td>162218.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>27800.0</td>\n",
       "      <td>12281.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>36702.0</td>\n",
       "      <td>42897.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>40201.0</td>\n",
       "      <td>48128.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>67267.0</td>\n",
       "      <td>37272.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>95203.0</td>\n",
       "      <td>21639.0</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>49994.0</td>\n",
       "      <td>161074.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>25315.0</td>\n",
       "      <td>13159.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>35615.0</td>\n",
       "      <td>42404.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>38943.0</td>\n",
       "      <td>47961.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>65482.0</td>\n",
       "      <td>36348.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>92525.0</td>\n",
       "      <td>21199.0</td>\n",
       "      <td>898.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Total                                      \\\n",
       "                          Mean Number with earnings Standard error   \n",
       "Total Both Sexes 2019  58544.0             167215.0          329.0   \n",
       "                 2018  55619.0             165179.0          296.0   \n",
       "                 2017  53536.0             163871.0          218.0   \n",
       "                 2016  51893.0             162218.0          217.0   \n",
       "                 2015  49994.0             161074.0          209.0   \n",
       "\n",
       "                      Not a high school graduate                       \\\n",
       "                                            Mean Number with earnings   \n",
       "Total Both Sexes 2019                    29278.0              11413.0   \n",
       "                 2018                    27037.0              12058.0   \n",
       "                 2017                    26832.0              12240.0   \n",
       "                 2016                    27800.0              12281.0   \n",
       "                 2015                    25315.0              13159.0   \n",
       "\n",
       "                                     High school graduate  \\\n",
       "                      Standard error                 Mean   \n",
       "Total Both Sexes 2019          552.0              39371.0   \n",
       "                 2018          481.0              38936.0   \n",
       "                 2017          383.0              38145.0   \n",
       "                 2016          559.0              36702.0   \n",
       "                 2015          422.0              35615.0   \n",
       "\n",
       "                                                           \\\n",
       "                      Number with earnings Standard error   \n",
       "Total Both Sexes 2019              42598.0          329.0   \n",
       "                 2018              42882.0          376.0   \n",
       "                 2017              42816.0          320.0   \n",
       "                 2016              42897.0          296.0   \n",
       "                 2015              42404.0          271.0   \n",
       "\n",
       "                      Some college/associate's degree                       \\\n",
       "                                                 Mean Number with earnings   \n",
       "Total Both Sexes 2019                         45091.0              46885.0   \n",
       "                 2018                         43053.0              46887.0   \n",
       "                 2017                         41507.0              47382.0   \n",
       "                 2016                         40201.0              48128.0   \n",
       "                 2015                         38943.0              47961.0   \n",
       "\n",
       "                                     Bachelor's degree                       \\\n",
       "                      Standard error              Mean Number with earnings   \n",
       "Total Both Sexes 2019          411.0           73163.0              42153.0   \n",
       "                 2018          416.0           71155.0              40231.0   \n",
       "                 2017          291.0           67763.0              39153.0   \n",
       "                 2016          277.0           67267.0              37272.0   \n",
       "                 2015          261.0           65482.0              36348.0   \n",
       "\n",
       "                                     Advanced degree                       \\\n",
       "                      Standard error            Mean Number with earnings   \n",
       "Total Both Sexes 2019          719.0        106766.0              24164.0   \n",
       "                 2018          676.0         99919.0              23118.0   \n",
       "                 2017          462.0         98369.0              22277.0   \n",
       "                 2016          508.0         95203.0              21639.0   \n",
       "                 2015          516.0         92525.0              21199.0   \n",
       "\n",
       "                                      \n",
       "                      Standard error  \n",
       "Total Both Sexes 2019         1440.0  \n",
       "                 2018         1186.0  \n",
       "                 2017          933.0  \n",
       "                 2016          909.0  \n",
       "                 2015          898.0  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"clean-pickle/taba-3.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, one could use pd.read_csv function to do so as well by specifying the header and index columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Total</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Not a high school graduate</th>\n",
       "      <th colspan=\"3\" halign=\"left\">High school graduate</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Some college/associate's degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Bachelor's degree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Advanced degree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Number with earnings</th>\n",
       "      <th>Standard error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Total</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Both Sexes</th>\n",
       "      <th>2019</th>\n",
       "      <td>58544.0</td>\n",
       "      <td>167215.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>29278.0</td>\n",
       "      <td>11413.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>39371.0</td>\n",
       "      <td>42598.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>45091.0</td>\n",
       "      <td>46885.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>73163.0</td>\n",
       "      <td>42153.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>106766.0</td>\n",
       "      <td>24164.0</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>55619.0</td>\n",
       "      <td>165179.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>27037.0</td>\n",
       "      <td>12058.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>38936.0</td>\n",
       "      <td>42882.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>43053.0</td>\n",
       "      <td>46887.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>71155.0</td>\n",
       "      <td>40231.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>99919.0</td>\n",
       "      <td>23118.0</td>\n",
       "      <td>1186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>53536.0</td>\n",
       "      <td>163871.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>26832.0</td>\n",
       "      <td>12240.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>38145.0</td>\n",
       "      <td>42816.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>41507.0</td>\n",
       "      <td>47382.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>67763.0</td>\n",
       "      <td>39153.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>98369.0</td>\n",
       "      <td>22277.0</td>\n",
       "      <td>933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51893.0</td>\n",
       "      <td>162218.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>27800.0</td>\n",
       "      <td>12281.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>36702.0</td>\n",
       "      <td>42897.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>40201.0</td>\n",
       "      <td>48128.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>67267.0</td>\n",
       "      <td>37272.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>95203.0</td>\n",
       "      <td>21639.0</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>49994.0</td>\n",
       "      <td>161074.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>25315.0</td>\n",
       "      <td>13159.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>35615.0</td>\n",
       "      <td>42404.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>38943.0</td>\n",
       "      <td>47961.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>65482.0</td>\n",
       "      <td>36348.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>92525.0</td>\n",
       "      <td>21199.0</td>\n",
       "      <td>898.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Total                                      \\\n",
       "                          Mean Number with earnings Standard error   \n",
       "Total Both Sexes 2019  58544.0             167215.0          329.0   \n",
       "                 2018  55619.0             165179.0          296.0   \n",
       "                 2017  53536.0             163871.0          218.0   \n",
       "                 2016  51893.0             162218.0          217.0   \n",
       "                 2015  49994.0             161074.0          209.0   \n",
       "\n",
       "                      Not a high school graduate                       \\\n",
       "                                            Mean Number with earnings   \n",
       "Total Both Sexes 2019                    29278.0              11413.0   \n",
       "                 2018                    27037.0              12058.0   \n",
       "                 2017                    26832.0              12240.0   \n",
       "                 2016                    27800.0              12281.0   \n",
       "                 2015                    25315.0              13159.0   \n",
       "\n",
       "                                     High school graduate  \\\n",
       "                      Standard error                 Mean   \n",
       "Total Both Sexes 2019          552.0              39371.0   \n",
       "                 2018          481.0              38936.0   \n",
       "                 2017          383.0              38145.0   \n",
       "                 2016          559.0              36702.0   \n",
       "                 2015          422.0              35615.0   \n",
       "\n",
       "                                                           \\\n",
       "                      Number with earnings Standard error   \n",
       "Total Both Sexes 2019              42598.0          329.0   \n",
       "                 2018              42882.0          376.0   \n",
       "                 2017              42816.0          320.0   \n",
       "                 2016              42897.0          296.0   \n",
       "                 2015              42404.0          271.0   \n",
       "\n",
       "                      Some college/associate's degree                       \\\n",
       "                                                 Mean Number with earnings   \n",
       "Total Both Sexes 2019                         45091.0              46885.0   \n",
       "                 2018                         43053.0              46887.0   \n",
       "                 2017                         41507.0              47382.0   \n",
       "                 2016                         40201.0              48128.0   \n",
       "                 2015                         38943.0              47961.0   \n",
       "\n",
       "                                     Bachelor's degree                       \\\n",
       "                      Standard error              Mean Number with earnings   \n",
       "Total Both Sexes 2019          411.0           73163.0              42153.0   \n",
       "                 2018          416.0           71155.0              40231.0   \n",
       "                 2017          291.0           67763.0              39153.0   \n",
       "                 2016          277.0           67267.0              37272.0   \n",
       "                 2015          261.0           65482.0              36348.0   \n",
       "\n",
       "                                     Advanced degree                       \\\n",
       "                      Standard error            Mean Number with earnings   \n",
       "Total Both Sexes 2019          719.0        106766.0              24164.0   \n",
       "                 2018          676.0         99919.0              23118.0   \n",
       "                 2017          462.0         98369.0              22277.0   \n",
       "                 2016          508.0         95203.0              21639.0   \n",
       "                 2015          516.0         92525.0              21199.0   \n",
       "\n",
       "                                      \n",
       "                      Standard error  \n",
       "Total Both Sexes 2019         1440.0  \n",
       "                 2018         1186.0  \n",
       "                 2017          933.0  \n",
       "                 2016          909.0  \n",
       "                 2015          898.0  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"clean-csv/taba-3.csv\", index_col=[0, 1, 2], header=[0, 1])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85dc16358c8135276cea6cc9ec3de3bb48d54befa5bbd5118bc882ec3e06d27f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
